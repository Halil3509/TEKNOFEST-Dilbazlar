{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae60561d-ca57-48e7-9a53-531cdbcfdb89",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be87c1f3-27f8-40a9-b8c3-6eb08c4624d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66defd6-9767-4276-b29b-d317419d35f9",
   "metadata": {},
   "source": [
    "## Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc0a12e-d883-4ea9-b153-8954e907b66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's really convenient. I should consider ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey do you have any favorite pet-related chari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I make it a point to network with professional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi I make it a habit to read industry-specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello plea bargaining can be seen as a practic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45094</th>\n",
       "      <td>It sounds cool . The rhythms look really diffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45095</th>\n",
       "      <td>How about the cinema ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45096</th>\n",
       "      <td>In some way , she is more modern .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45097</th>\n",
       "      <td>What's the house rent ? When is the rent due ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45098</th>\n",
       "      <td>What's the weather like in your country ? I su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45099 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text\n",
       "0      That's really convenient. I should consider ge...\n",
       "1      Hey do you have any favorite pet-related chari...\n",
       "2      I make it a point to network with professional...\n",
       "3      Hi I make it a habit to read industry-specific...\n",
       "4      Hello plea bargaining can be seen as a practic...\n",
       "...                                                  ...\n",
       "45094  It sounds cool . The rhythms look really diffi...\n",
       "45095                             How about the cinema ?\n",
       "45096                 In some way , she is more modern .\n",
       "45097  What's the house rent ? When is the rent due ?...\n",
       "45098  What's the weather like in your country ? I su...\n",
       "\n",
       "[45099 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Data/normal_dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15e70a9-8fef-4a70-b307-f1bcf0574852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"That's really convenient. I should consider getting a smartwatch too.\",\n",
       "       'Hey do you have any favorite pet-related charities or organizations?',\n",
       "       'I make it a point to network with professionals in our field and engage in discussions on industry forums. It helps me stay current.',\n",
       "       ..., 'In some way , she is more modern .',\n",
       "       \"What's the house rent ? When is the rent due ? And how much security deposit do you require ?\",\n",
       "       \"What's the weather like in your country ? I suppose it must be warmer than here .\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c9ef8b-fbeb-4f75-8b8c-0f122be83bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c974a4c3-5809-45a8-a392-fa4f364883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45099 entries, 0 to 45098\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    45099 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 352.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244eb4f0-905e-49c9-be19-b5530c74a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45099 entries, 0 to 45098\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    45099 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 352.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed39881-d739-425a-a599-361574bcc309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's really convenient. I should consider getting a smartwatch too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey do you have any favorite pet-related charities or organizations?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I make it a point to network with professionals in our field and engage in discussions on industry forums. It helps me stay current.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi I make it a habit to read industry-specific publications and research papers. They provide in-depth analysis and keep me informed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello plea bargaining can be seen as a practical approach to resolving cases efficiently and reducing the caseload of the courts.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    Text\n",
       "0                                                                  That's really convenient. I should consider getting a smartwatch too.\n",
       "1                                                                   Hey do you have any favorite pet-related charities or organizations?\n",
       "2   I make it a point to network with professionals in our field and engage in discussions on industry forums. It helps me stay current.\n",
       "3  Hi I make it a habit to read industry-specific publications and research papers. They provide in-depth analysis and keep me informed.\n",
       "4      Hello plea bargaining can be seen as a practical approach to resolving cases efficiently and reducing the caseload of the courts."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f494ec9-1410-4bc6-92fb-39f05b320e3c",
   "metadata": {},
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-tr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Çeviri fonksiyonunu tanımla\n",
    "def translate_text(text):\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# DataFrame'deki her satır için çeviri işlemi uygula ve yeni bir kolona ekle\n",
    "data['Translated_Text'] = data['Text'].apply(translate_text)\n",
    "\n",
    "# Sonuçları göster\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81098c73-25c1-49e9-9a55-69ab399cc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halilibrahim.hatun\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(57060, 1024, padding_idx=57059)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=57060, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-tr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c229d8c-23d3-432e-847c-ae051c2e1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Process: 100%|████████████████████████████████████████████████████████████| 11275/11275 [6:44:37<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "def batch_translate_text(texts, batch_size=4):\n",
    "    translated_texts = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating Process\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        translated = model.generate(**inputs)\n",
    "        translated_batch = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "        translated_texts.extend(translated_batch)\n",
    "        del inputs, translated  # Free up memory\n",
    "        torch.cuda.empty_cache()\n",
    "    return translated_texts\n",
    "\n",
    "texts = data['Text'].tolist()\n",
    "translated_texts = batch_translate_text(texts)\n",
    "\n",
    "data['Translated_Text'] = translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6d471-08cf-45cc-b195-8ff100950231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05dc134e-df43-46ff-8dfd-2315d8a54b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"../Data/temp.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f3815-5a4e-42e0-959f-a318e13f1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b1b2f-94dc-4077-9211-0d6ef29f1277",
   "metadata": {},
   "source": [
    "data.to_csv(\"agoraphobia_translated_to_tr\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1197b1-898c-4626-beda-e326e15aa4db",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"agoraphobia_translated_to_tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60491970-4954-4666-8775-3a3a3063a598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Psynexa Torch GPU (Python 3.11)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
